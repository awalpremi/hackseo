{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Project: SEO Helper\n",
    "Idea: A simple tool to replicate SEO articles from others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEPS\n",
    "## 1. Grab XML sitemap for a given website\n",
    "## 2. Parse it to get article URLs\n",
    "## 3. Scrape or infer via URL the content\n",
    "## 4. Recreate content using AI \n",
    "## 5. Publish on your own website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Get XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pick directory to save the sitemap\n",
    "import os\n",
    "download_folder = 'sitemaps'  # Replace with the path to your desired folder\n",
    "if not os.path.exists(download_folder):\n",
    "    os.makedirs(download_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to find the sitemap URL\n",
    "import requests\n",
    "\n",
    "#Set the header, pretend to be googlebot (optional)\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.4 Safari/605.1.15'\n",
    "}\n",
    "\n",
    "\n",
    "def find_sitemap_url(robots_url, headers):\n",
    "    \"\"\"Attempt to find the sitemap URL in the robots.txt file.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(robots_url, headers=headers)\n",
    "        response.raise_for_status()  # Raises an HTTPError if the response was an error\n",
    "        for line in response.text.splitlines():\n",
    "            if line.startswith('Sitemap:'):\n",
    "                return [line.split(':', 1)[1].strip()]\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching or parsing robots.txt: {e}\")\n",
    "    return []\n",
    "\n",
    "def try_common_sitemap_urls(base_url, headers):\n",
    "    \"\"\"Attempt to directly access common sitemap URLs.\"\"\"\n",
    "    common_paths = ['/sitemap.xml', '/sitemap_index.xml', '/page-sitemap.xml', '/post-sitemap.xml', '/post-sitemap2.xml','/event-sitemap.xml','/news-sitemap.xml','/sitemap_index.xml','/prodcut-sitemap.xml','/prodcuts-sitemap.xml','/partners-sitemap.xml']\n",
    "    found_sitemaps = []\n",
    "    for path in common_paths:\n",
    "        url = base_url.rstrip('/') + path\n",
    "        try:\n",
    "            response = requests.head(url, headers=headers)\n",
    "            if response.status_code == 200:\n",
    "                found_sitemaps.append(url)\n",
    "        except Exception as e:\n",
    "            print(f\"Error checking URL {url}: {e}\")\n",
    "    return found_sitemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://freshprinceofstandarderror.com/sitemap_index.xml',\n",
       " 'https://freshprinceofstandarderror.com/page-sitemap.xml',\n",
       " 'https://freshprinceofstandarderror.com/post-sitemap.xml',\n",
       " 'https://freshprinceofstandarderror.com/sitemap_index.xml']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try_common_sitemap_urls('https://freshprinceofstandarderror.com/', headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: a-e-i-o.com/sitemap.xml\n",
      "Downloaded sitemap: freshprinceofstandarderror.com_sitemap_index.xml\n",
      "Downloaded sitemap: freshprinceofstandarderror.com_page-sitemap.xml\n",
      "Downloaded sitemap: freshprinceofstandarderror.com_post-sitemap.xml\n",
      "Downloaded sitemap: freshprinceofstandarderror.com_sitemap_index.xml\n"
     ]
    }
   ],
   "source": [
    "#Download the sitemap to your directory\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "## Use urlparse to get a decent name for the file\n",
    "### Example\n",
    "print(f'Example: {urlparse('https://a-e-i-o.com/sitemap.xml').netloc+urlparse('https://a-e-i-o.com/sitemap.xml').path}')\n",
    "\n",
    "def download_sitemap(url, headers, folder):\n",
    "    \"\"\"Download the sitemap content and save to the specified folder.\"\"\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status()  # Ensure we notice bad responses\n",
    "    \n",
    "    # Use urlparse to get the domain and path to create a unique filename\n",
    "    url_parts = urlparse(url)\n",
    "    domain = url_parts.netloc.replace(\"www.\", \"\")  # Remove 'www.' if present\n",
    "    path = url_parts.path.lstrip('/').replace('/', '_')  # Replace slashes with underscores\n",
    "    filename = f\"{domain}_{path}\" if path else domain  # Construct filename using domain and path\n",
    "    \n",
    "    file_path = os.path.join(folder, filename)\n",
    "    \n",
    "    with open(file_path, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    print(f\"Downloaded sitemap: {filename}\")\n",
    "\n",
    "#Download whatever you find.\n",
    "for maps in try_common_sitemap_urls('https://freshprinceofstandarderror.com', headers):\n",
    "    download_sitemap(maps, headers, download_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Parse XML to get all the URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://freshprinceofstandarderror.com/?page_id=8\n",
      "https://freshprinceofstandarderror.com/product/analytics-set-up-for-everybody/\n",
      "https://freshprinceofstandarderror.com/uncategorized/draft-setting-up-git-and-github-for-unity-projects/\n",
      "https://freshprinceofstandarderror.com/ai/games-with-reinforcement-learning/\n",
      "https://freshprinceofstandarderror.com/finance/fear-and-greed-index-data-in-python/\n",
      "https://freshprinceofstandarderror.com/general/12-days-of-christmath/\n",
      "https://freshprinceofstandarderror.com/ai/fashion-mnist-computer-vision/\n",
      "https://freshprinceofstandarderror.com/general/sql-for-everybody/\n",
      "https://freshprinceofstandarderror.com/ai/unsupervised-clustering-to-understand-your-users/\n",
      "https://freshprinceofstandarderror.com/ai/setting-up-your-data-science-environment/\n",
      "https://freshprinceofstandarderror.com/product/automating-your-python-scripts-in-the-cloud/\n",
      "https://freshprinceofstandarderror.com/ai/robust-principal-component-analysis/\n",
      "https://freshprinceofstandarderror.com/product/slack-bots-for-product-managers/\n",
      "https://freshprinceofstandarderror.com/finance/decomposing-portfolio-returns-into-factors/\n",
      "https://freshprinceofstandarderror.com/product/systems-thinking-for-product-managers-part-1/\n",
      "https://freshprinceofstandarderror.com/product/systems-thinking-for-product-managers-part-2/\n",
      "https://freshprinceofstandarderror.com/finance/accounting-ratios-for-apes/\n",
      "https://freshprinceofstandarderror.com/product/tips-for-improving-webpage-accessibility/\n",
      "https://freshprinceofstandarderror.com/product/marketing-in-brief-a-summary/\n",
      "https://freshprinceofstandarderror.com/ai/accessible-nlp-for-analysts-marketers-and-product-managers/\n",
      "https://freshprinceofstandarderror.com/product/creating-personas-and-journey-maps/\n",
      "https://freshprinceofstandarderror.com/general/what-is-a-standard-error/\n",
      "https://freshprinceofstandarderror.com/finance/track-earnings-dates-with-yahoo-finance-and-google-calendar-api/\n",
      "https://freshprinceofstandarderror.com/ai/understand-matrix-decomposition-to-understand-lora-and-qlora/\n",
      "https://freshprinceofstandarderror.com/finance/economics-like-an-economist/\n",
      "https://freshprinceofstandarderror.com/ai/data-science-environment-setup-on-apple-mac-silicon-and-mlx-installation/\n",
      "https://freshprinceofstandarderror.com/ai/using-llms-locally-with-lm-studio/\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "\n",
    "def extract_urls_from_sitemap(file_path):\n",
    "    \"\"\"Extracts <loc> URLs from a sitemap XML file.\"\"\"\n",
    "    with open(file_path, 'rb') as f:\n",
    "        tree = etree.parse(f)\n",
    "    \n",
    "    # Define the namespace map to use with XPath\n",
    "    ns_map = {'ns': 'http://www.sitemaps.org/schemas/sitemap/0.9'}\n",
    "    \n",
    "    # Find all <loc> elements in the XML file\n",
    "    loc_elements = tree.xpath('//ns:url/ns:loc', namespaces=ns_map)\n",
    "    \n",
    "    urls = []\n",
    "    for loc in loc_elements:\n",
    "        # Extract the text content within CDATA\n",
    "        url = loc.text\n",
    "        urls.append(url)\n",
    "    \n",
    "    return urls\n",
    "\n",
    "\n",
    "# Call the function and print the results\n",
    "urls = extract_urls_from_sitemap('sitemaps/freshprinceofstandarderror.com_post-sitemap.xml')\n",
    "for url in urls:\n",
    "    print(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape or Infer via URL the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>URL</th>\n",
       "      <th>Description</th>\n",
       "      <th>Known Sitemap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FPSE</td>\n",
       "      <td>https://freshprinceofstandarderror.com/</td>\n",
       "      <td>AI Blog</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FPSE</td>\n",
       "      <td>https://freshprinceofstandarderror.com/</td>\n",
       "      <td>AI Blog</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Name                                      URL Description  Known Sitemap\n",
       "0  FPSE  https://freshprinceofstandarderror.com/     AI Blog            NaN\n",
       "1  FPSE  https://freshprinceofstandarderror.com/     AI Blog            NaN"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Put competitors in the CSV file to be organized. You just need the URL of their website.\n",
    "import pandas as pd\n",
    "df = pd.read_csv('competition.csv',sep=',',header=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded sitemap: freshprinceofstandarderror.com_sitemap_index.xml\n",
      "Downloaded sitemap: freshprinceofstandarderror.com_page-sitemap.xml\n",
      "Downloaded sitemap: freshprinceofstandarderror.com_post-sitemap.xml\n",
      "Downloaded sitemap: freshprinceofstandarderror.com_sitemap_index.xml\n"
     ]
    }
   ],
   "source": [
    "dem_urls = []\n",
    "#Drop duplicates incase you have any and go through all the functions\n",
    "for url in df['URL'].drop_duplicates().to_list():\n",
    "    for xmaps in try_common_sitemap_urls(url, headers):\n",
    "        download_sitemap(xmaps, headers, download_folder)\n",
    "\n",
    "sitemap_files = [f for f in os.listdir(download_folder) if f.endswith('.xml')]\n",
    "for file in sitemap_files:\n",
    "    urls = extract_urls_from_sitemap(f'{download_folder}/{file}')\n",
    "    for url in urls:\n",
    "        dem_urls.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://freshprinceofstandarderror.com/product...</td>\n",
       "      <td>Web analytics set-up for everybody - Product</td>\n",
       "      <td>Web analytics set-up for everybody - Product f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://freshprinceofstandarderror.com/uncateg...</td>\n",
       "      <td>Draft: Setting up git and github for unity pro...</td>\n",
       "      <td>Draft: Setting up git and github for unity pro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 URL  \\\n",
       "0  https://freshprinceofstandarderror.com/product...   \n",
       "1  https://freshprinceofstandarderror.com/uncateg...   \n",
       "\n",
       "                                               Title  \\\n",
       "0       Web analytics set-up for everybody - Product   \n",
       "1  Draft: Setting up git and github for unity pro...   \n",
       "\n",
       "                                                Text  \n",
       "0  Web analytics set-up for everybody - Product f...  \n",
       "1  Draft: Setting up git and github for unity pro...  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning the URLs by stripping whitespace\n",
    "clean_urls = [url.strip() for url in dem_urls]\n",
    "\n",
    "\n",
    "#Scrape or not to scrape?\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_title_and_text(url):\n",
    "    try:\n",
    "        # Fetch the content from url\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raises an HTTPError if the response status code is 4XX or 5XX\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Extract title\n",
    "        title = soup.title.text if soup.title else 'No Title Found'\n",
    "\n",
    "        # Extract all text\n",
    "        texts = soup.get_text(separator=' ', strip=True)\n",
    "        \n",
    "        return title, texts\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching {url}: {e}\")\n",
    "        return 'Error', 'Error'\n",
    "\n",
    "## Lets hand pick a few links, you can do as many, dont be a prick though.\n",
    "articles_scraped = []\n",
    "for url in clean_urls[1:3]:\n",
    "    title, all_text = scrape_title_and_text(url)\n",
    "    articles_scraped.append({'URL': url, 'Title': title, 'Text': all_text})\n",
    "\n",
    "df_articles = pd.DataFrame(articles_scraped)\n",
    "df_articles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Yikes, recreate using AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv #optional, just use your key\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv('OAI_API_KEY'))\n",
    "\n",
    "prooomp = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "            ]\n",
    "\n",
    "#You can use GPT 4 if you're loaded \"gpt-4-0125-preview\"\n",
    "def get_article(prompt,model=\"gpt-3.5-turbo\"):\n",
    "    completion = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=prompt,\n",
    "    temperature=0.7,\n",
    "    seed=0)\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "get_article(prooomp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a half baked prompt that puts in the article\n",
    "personality = 'Goth cheerleader that is really into tech and darkness with a lot of personality'\n",
    "article_prompt = [\n",
    "            {\"role\": \"system\", \"content\": f\"You are a SEO content writer and {personality}. You have this draft that you will edit and make it sound better for your cool blog. Also make it concise and to the point. Return back markdown format and remove all hyperlinks.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Article:{df_articles['Text'][0]}\"}\n",
    "            ]\n",
    "\n",
    "article = get_article(article_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Web Analytics Set-Up Made Easy for Everyone\n",
       "\n",
       "Hey there! Setting up web analytics and optimization tools may seem overwhelming, especially if you're not an expert in data or product management. But fear not, it's not as daunting as it appears. It all begins with **Google Tag Manager**.\n",
       "\n",
       "At many of my previous workplaces, we utilized a containerized tag management system like **Google Tag Manager (GTM)**. It simplifies trying out new data collection tools and onboarding UX tools swiftly without relying on developers for every new tool.\n",
       "\n",
       "Here's a quick rundown to get started with Google Tag Manager:\n",
       "\n",
       "1. Create a Google Tag Manager account (selling your soul to Google is optional 😉).\n",
       "2. Install a reputable plugin on your website to insert GTM snippets.\n",
       "3. Utilize tools like **Google Analytics**, **Hotjar**, onboarding tools, live chat support, and optimization tools.\n",
       "\n",
       "Setting up **Google Analytics**:\n",
       "\n",
       "1. Create a new tag in GTM.\n",
       "2. Configure the tag for Google Analytics using GA4 for enhanced features.\n",
       "3. Input your tracking code (create a Google Analytics account if you don't have one yet).\n",
       "4. Publish the tag in GTM to make the changes live.\n",
       "\n",
       "Setting up **Hotjar**:\n",
       "\n",
       "1. Sign up for a free Hotjar account.\n",
       "2. Follow the onboarding process to receive a code snippet.\n",
       "3. Set up session targeting to capture data effectively.\n",
       "\n",
       "By mastering these basics, you can expand your knowledge to incorporate more cutting-edge tools used by forward-thinking organizations. Remember:\n",
       "\n",
       "- Install Google Tag Manager.\n",
       "- Add new tags and configure essential tools like GA and Hotjar.\n",
       "- Dive deeper into custom triggers in GTM and effectively use analytics tools.\n",
       "\n",
       "And hey, if you're into data analysis, why not explore setting up your python environment as well? Check out more cool stuff on my blog!\n",
       "\n",
       "Stay tech-savvy and embrace the darkness! 🖤🦇"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"# Web Analytics Set-Up Made Easy for Everyone\\n\\nHey there! Setting up web analytics and optimization tools may seem overwhelming, especially if you're not an expert in data or product management. But fear not, it's not as daunting as it appears. It all begins with **Google Tag Manager**.\\n\\nAt many of my previous workplaces, we utilized a containerized tag management system like **Google Tag Manager (GTM)**. It simplifies trying out new data collection tools and onboarding UX tools swiftly without relying on developers for every new tool.\\n\\nHere's a quick rundown to get started with Google Tag Manager:\\n\\n1. Create a Google Tag Manager account (selling your soul to Google is optional 😉).\\n2. Install a reputable plugin on your website to insert GTM snippets.\\n3. Utilize tools like **Google Analytics**, **Hotjar**, onboarding tools, live chat support, and optimization tools.\\n\\nSetting up **Google Analytics**:\\n\\n1. Create a new tag in GTM.\\n2. Configure the tag for Google Analytics using GA4 for enhanced features.\\n3. Input your tracking code (create a Google Analytics account if you don't have one yet).\\n4. Publish the tag in GTM to make the changes live.\\n\\nSetting up **Hotjar**:\\n\\n1. Sign up for a free Hotjar account.\\n2. Follow the onboarding process to receive a code snippet.\\n3. Set up session targeting to capture data effectively.\\n\\nBy mastering these basics, you can expand your knowledge to incorporate more cutting-edge tools used by forward-thinking organizations. Remember:\\n\\n- Install Google Tag Manager.\\n- Add new tags and configure essential tools like GA and Hotjar.\\n- Dive deeper into custom triggers in GTM and effectively use analytics tools.\\n\\nAnd hey, if you're into data analysis, why not explore setting up your python environment as well? Check out more cool stuff on my blog!\\n\\nStay tech-savvy and embrace the darkness! 🖤🦇\""
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "display(Markdown(article))\n",
    "\n",
    "\n",
    "article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-UZstB1rwhwLX4qqfVtDrBHuG/user-7p8CaNbwWrGCMfUmlL6MnjLo/img-iQ6qxpJtSWdb4zQzwIkj5aYA.png?st=2024-03-05T19%3A51%3A19Z&se=2024-03-05T21%3A51%3A19Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-03-05T15%3A55%3A21Z&ske=2024-03-06T15%3A55%3A21Z&sks=b&skv=2021-08-06&sig=vRW7CyRkVvYDjPlx29Au3gJ%2BJ6rNZ8Q8ewvGR3YGNWs%3D\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# Generate a cover image using the first few words of the article\n",
    "\n",
    "response = client.images.generate(\n",
    "  model=\"dall-e-3\",\n",
    "  prompt=article[0:100],\n",
    "  size=\"1024x1024\",\n",
    "  quality=\"standard\",\n",
    "  n=1,\n",
    ")\n",
    "\n",
    "image_url = response.data[0].url\n",
    "\n",
    "display(Image(url=image_url))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload thousands of articles directly to your CMS\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Wait.. This is too powerful and dangerous. I can't show any more. You can sabotage websites, make money from clicks, take over thousands of copywriting jobs and be a big prick. Think that is far-fetched? This article is actually to raise awareness of what people are already doing and what is possible."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
